{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './modules')\n",
    "from helpers import read_in_dataset, preprocess, apply_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********************Reading in the data/train.csv dataset**********************\n",
      "\n",
      "it has 891 rows and 12 columns\n",
      "\n",
      "*************************it has the following columns\n",
      "**************************\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "\n",
      "************************the first 5 rows looks like this************************\n",
      "\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "**********************Reading in the data/test.csv dataset**********************\n",
      "\n",
      "it has 418 rows and 11 columns\n",
      "\n",
      "*************************it has the following columns\n",
      "**************************\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "\n",
      "************************the first 5 rows looks like this************************\n",
      "\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "train = read_in_dataset('data/train.csv', verbose = True)\n",
    "test = read_in_dataset('data/test.csv',verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "imputing Embarked using mode from the training set......\n",
      "\n",
      "2 Embarked imputed with S\n",
      "\n",
      "No NaN in norm_Fare\n",
      "\n",
      "\n",
      "imputing Age using aggregated info baesd on name_title_adv from the training set.......\n",
      "\n",
      "filled 1 title Dr with age value 42.0\n",
      "filled 4 title Master with age value 4.574166666666667\n",
      "filled 36 title Miss with age value 21.773972602739725\n",
      "filled 119 title Mr with age value 32.368090452261306\n",
      "filled 17 title Mrs with age value 35.898148148148145\n",
      "\n",
      "No NaN in Embarked\n",
      "\n",
      "\n",
      "imputing norm_Fare using median from the training set......\n",
      "\n",
      "1 norm_Fare imputed\n",
      "\n",
      "\n",
      "replaced 1 Dona with Mr\n",
      "\n",
      "imputing Age using aggregated info baesd on name_title_adv from the training set.......\n",
      "\n",
      "filled 4 title Master with age value 4.574166666666667\n",
      "filled 14 title Miss with age value 21.773972602739743\n",
      "filled 57 title Mr with age value 32.36809045226126\n",
      "filled 10 title Mrs with age value 35.898148148148145\n",
      "filled 1 title title_survive with age value 32.857142857142854\n"
     ]
    }
   ],
   "source": [
    "#based on EDA, the following variables should be included as features\n",
    "#Pclass, name_title_adv, Sex, Age, Sibsp, Parch, Fare, Embarked, cabin_total, cabin_firstletter, ticket_firstletter\n",
    "train = preprocess(train,train)\n",
    "test = preprocess(test,train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "Survived              891 non-null int64\n",
      "Pclass                891 non-null object\n",
      "Sex                   891 non-null object\n",
      "Age                   891 non-null float64\n",
      "SibSp                 891 non-null int64\n",
      "Parch                 891 non-null int64\n",
      "Embarked              891 non-null object\n",
      "norm_Fare             891 non-null float64\n",
      "name_title_adv        891 non-null object\n",
      "Ticket_firstletter    891 non-null object\n",
      "Cabin_firstletter     891 non-null object\n",
      "Cabin_total           891 non-null int64\n",
      "dtypes: float64(2), int64(4), object(6)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "Pclass                418 non-null object\n",
      "Sex                   418 non-null object\n",
      "Age                   418 non-null float64\n",
      "SibSp                 418 non-null int64\n",
      "Parch                 418 non-null int64\n",
      "Embarked              418 non-null object\n",
      "norm_Fare             418 non-null float64\n",
      "name_title_adv        418 non-null object\n",
      "Ticket_firstletter    418 non-null object\n",
      "Cabin_firstletter     418 non-null object\n",
      "Cabin_total           418 non-null int64\n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge train and test to create a consistent dummy-variable set across train and test\n",
    "test['Survived'] = np.nan\n",
    "train['train_test'] = 'train'\n",
    "test['train_test'] = 'test'\n",
    "all_data = train.append(test, sort = True)\n",
    "all_dummies = pd.get_dummies(all_data)\n",
    "X_train = all_dummies[all_dummies['train_test_train']==1].drop(columns = \n",
    "                                                               ['Survived','train_test_test','train_test_train'])\n",
    "Y_train = all_dummies.loc[all_dummies['train_test_train']==1, 'Survived']\n",
    "X_test = all_dummies[all_dummies['train_test_test']==1].drop(columns = \n",
    "                                                             ['Survived','train_test_test','train_test_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following columns are scaled:\n",
      "\n",
      "['Age', 'Cabin_total', 'Parch', 'SibSp', 'norm_Fare']\n"
     ]
    }
   ],
   "source": [
    "#scale the numeric variables in both train and test, fit to train only\n",
    "both = apply_scaler(X_train, X_test)\n",
    "X_train_scaled = both[0]\n",
    "X_test_scaled = both[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.to_csv('X_train.csv',index = False)\n",
    "Y_train.to_csv('Y_train.csv',index = False, header = False)\n",
    "X_test_scaled.to_csv('X_test.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
